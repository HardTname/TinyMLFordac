# Lecture 2 - Basics of Neural Networks

## 1.神经网络的基本术语

Batch size：批量大小。是指每次迭代使用的样本数量，影响训练速度，内存消耗等

- neuron：神经元。神经网络的最小计算单位，相当于一个 “加权求和+激活函数”的小模块
  - 具体来说，模拟生物神经元的过程：接受输入，处理信息，产生输出。
  - 接收输入可能有多个（$x_1,x_2,x_3,\cdots,x_n$），一般考虑实数。
  - 处理信息包括两部分：线性部分和非线性部分。
    - 线性部分产生一个单值：$z=\sum w_i x_i + b$，这是一个较一般形式的线性函数。
      - $w_i$被称为权重。每个输入都有一个对应的权重。
      - $b$被称为偏置。

    - 非线性部分：激活函数。是一个单值函数$f(z)$（接收一个输入）。
      - 加权和 `z` 的结果是一个任意实数。
      - 我们需要一个机制来决定这个神经元“是否被激活”以及“激活到何种程度”。这就是激活函数的工作。
      - 引入非线性：如果没有激活函数，无论神经网络有多少层，最终都等价于一个简单的线性回归模型。

    - 处理信息就是这样
      - 通过线性多值函数将输入转化成一个值，
      - 再通过一个非线性单值函数得到最终的结果。

  - 产生一个输出。

- synapses：突触。神经元之间相连的“权重连接”，对应于深度学习中的 `weights` 
  - 指两个神经元之间的连接权值，
    - 比如A->B的突触权值为0.3，
    - 意味着B在接受输入进行加权求和引入偏置代入激活函数时的线性加权求和部分对来自A的输入的权值为0.3
    - 对应上面的A的输出给B的$x$的权值$w$

  - 一般来说，在模型训练阶段，突触的权值是动态变化的，这也是模型训练的重要目标（确定一套良好的突触权值）
  - 在模型训练好后，突触权值一般是不变的。可以用这套权值投入应用和解决问题。
  - 一般来说，突触是单向的。在标准的前馈神经网络中，如果有A->B的连接，就根本不存在B->A的连接。
  - 在循环神经网络中，可能会发生时间上的有A->B连接又有B->A连接的两个过程，但权值是否一样无从保证。
  - 因此可以认为突触是单向的，即使有A->B又有B->A，最好也理解成两个不同的独立的单向。

- activation：激活。神经元1输出的非线性处理结果，如 `ReLU` , `Sigmoid`
  - 激活函数。
  - 正如上面所说的，位于一个神经元的内部计算过程的最后一步


> [!Note]
>
> 激活函数activation Function的意义：引入非线性，让模型能处理复杂关系
>
> 容易想象，如果没有激活函数，或者说如果激活函数都是线性的，那么整个神经网络过程中发生的任何计算都会是线性的
>
> 因此对于特定的输入，给出输出，都会是一个线性的行为。
>
> 非线性激活函数带来/提供了巨大的可能，使得神经网络能够成为“万能函数逼近器”

- feature：特征。输入或中间层输出的向量，用于表示信息，“神经网络理解世界的方式”

- weight/parameters：权重/参数。模型训练过程中学习和调整的数值，决定模型的行为

## 神经网络的常见构建模块

- Fully-Conneted（全连接层）

​	每个输入和输出都相连，用于结构简单的问题

- Convolution （卷积）

​	用于图像、语言等，局部连接，参数更少

- Grouped Convolution （分组卷积）

​	把通道分成多组，各组单独卷积，减少计算量

- Depthwise Convolution （深度可分离卷积）

​	每个通道分别卷积再混合，非常高效

- Pooling （池化）

​	降低分辨率，减小特征图大小，提高感受野

- Normalization （归一化）

- Transformer （变压器结构）

​	现在最主流的结构，基于attention（注意力机制）

## 神经网络的效率指标

这些指标用于衡量模型的有效性与性能：

- #Parameters（参数量）：模型存储大小。
- Model Size（模型大小）：以 MB、GB 测量。
- Peak #Activations（激活峰值）：训练时内存占用关键指标。
- MAC（乘加运算次数）
- FLOP / FLOPS（浮点运算 / 每秒浮点运算）
- OP / OPS（操作数 / 每秒操作数）
- Latency（延迟）：一次推理需要的时间。
- Throughput（吞吐量）：每秒能处理多少数据（如 1000 推理/秒）。

**这些指标在 AI 算法面向硬件部署特别重要！**